{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "joint-hardware",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Type\n",
    "from simulator import CovertGenerator, DarkGenerator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incident-shore",
   "metadata": {},
   "source": [
    "## Generator & Reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "higher-arbitration",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ba_generator(min_n: int=20, max_n: int=30, m: int=2) -> Type[nx.classes.graph.Graph]:\n",
    "    n = np.random.randint(max_n - min_n + 1) + min_n\n",
    "    return nx.barabasi_albert_graph(n ,m)\n",
    "\n",
    "def covert_generator(min_n: int=20, max_n: int=30, density: int=0.1):\n",
    "    generator = CovertGenerator(min_n, max_n, density)\n",
    "    generator.simulate()\n",
    "    return generator.G\n",
    "\n",
    "def dark_generator(min_n: int=20, max_n: int=30, density: int=0.1):\n",
    "    generator = DarkGenerator(min_n, max_n, density)\n",
    "    generator.simulate()\n",
    "    return generator.G\n",
    "\n",
    "def write_gml(G: Type[nx.classes.graph.Graph], data_dir: str, file_name: str) -> None:\n",
    "    nx.write_gml(G, data_dir+file_name)\n",
    "    \n",
    "def read_gml(data_dir: str, file_name: str) -> Type[nx.classes.graph.Graph]:\n",
    "    G = nx.read_gml(data_dir + file_name)\n",
    "    return nx.relabel_nodes(G, lambda x: int(x))\n",
    "\n",
    "def get_real_graph(data_dir: str, file_name: str) -> Type[nx.classes.graph.Graph]:\n",
    "    return read_gml(data_dir, file_name)\n",
    "\n",
    "def getRobustness(g: Type[nx.classes.graph.Graph], sol: int):\n",
    "    G = g.copy()\n",
    "    G_size = G.number_of_nodes()\n",
    "    GCCsize = len(max(nx.connected_components(G), key=len))\n",
    "    \n",
    "    removed = [n for n in G.neighbors(int(sol))] + [int(sol)]\n",
    "    for n in removed:\n",
    "        G.remove_node(n)\n",
    "        \n",
    "    newGCCsize = len(max(nx.connected_components(G), key=len))\n",
    "\n",
    "    return (GCCsize - newGCCsize) / (G_size * G_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "stuffed-forward",
   "metadata": {},
   "outputs": [],
   "source": [
    "def HXA(g: Type[nx.classes.graph.Graph], method: str) -> (list, list):\n",
    "    # 'HDA', 'HBA', 'HCA', 'HPRA'\n",
    "    sol = []\n",
    "    reward = []\n",
    "    G = g.copy()\n",
    "    while (nx.number_of_edges(G)>0):\n",
    "        if method == 'HDA':\n",
    "            dc = nx.degree_centrality(G)\n",
    "        elif method == 'HBA':\n",
    "            dc = nx.betweenness_centrality(G)\n",
    "        elif method == 'HCA':\n",
    "            dc = nx.closeness_centrality(G)\n",
    "        elif method == 'HPRA':\n",
    "            dc = nx.pagerank(G)\n",
    "        keys = list(dc.keys())\n",
    "        values = list(dc.values())\n",
    "        maxTag = np.argmax(values)\n",
    "        node = keys[maxTag]\n",
    "        \n",
    "        reward.append(getRobustness(G, int(node)))\n",
    "        \n",
    "        sol.append(int(node))\n",
    "        removed = [n for n in G.neighbors(int(node))] + [int(node)]\n",
    "        for n in removed:\n",
    "            G.remove_node(n)\n",
    "\n",
    "    return sol, reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outstanding-angola",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "defensive-riding",
   "metadata": {},
   "source": [
    "## BA & Covert & Dark "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4091b764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iters = 100\n",
    "# for i in range(iters):\n",
    "#     G = ba_generator(min_n=200, max_n=200, m=1)\n",
    "#     write_gml(G, data_dir=\"./ba/\", file_name=f\"g_{i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "changed-integer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iters = 100\n",
    "# for i in range(iters):\n",
    "#     G = dark_generator(min_n=200, max_n=200, density=0.01)\n",
    "#     write_gml(G, data_dir=\"./dark/\", file_name=f\"g_{i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "sized-durham",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iters = 100\n",
    "# for i in range(iters): \n",
    "#     G = covert_generator(min_n=200, max_n=200, density=0.01)\n",
    "#     write_gml(G, data_dir=\"./covert/\", file_name=f\"g_{i}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "human-miracle",
   "metadata": {},
   "source": [
    "## Heuristic based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "damaged-synthetic",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    hxa_dct = dict()\n",
    "    reward_dct = dict()\n",
    "    g = read_gml(data_dir=\"./ba/\", file_name=f\"g_{i}\")\n",
    "\n",
    "    for method in ['HDA', 'HBA', 'HCA', 'HPRA']:\n",
    "        sol, reward = HXA(g=g, method=method)\n",
    "        hxa_dct[method] = sol\n",
    "        reward_dct[method] = np.cumsum(reward).tolist()\n",
    "        \n",
    "    with open(f\"./ba/node_hist/g_{i}.json\", \"w\") as json_file:\n",
    "        json.dump(hxa_dct, json_file) \n",
    "    with open(f\"./ba/reward_hist/g_{i}.json\", \"w\") as json_file:\n",
    "        json.dump(reward_dct, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5cda7e",
   "metadata": {},
   "source": [
    "## FINDER "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "joined-projector",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    finder_dct = dict()\n",
    "    reward_lst = []\n",
    "    g = read_gml(data_dir=\"./ba/\", file_name=f\"g_{i}\")\n",
    "    df = pd.read_csv(f\"./ba/finder_node_hist/g_{i}.txt\", header=None).rename(columns={0: \"round\", 1: \"node\"})\n",
    "    \n",
    "    for _, (round, node) in df.iterrows():\n",
    "        try:\n",
    "            reward_lst.append(getRobustness(g, int(node)))\n",
    "            removed = [n for n in g.neighbors(int(node))] + [int(node)]\n",
    "            for n in removed:\n",
    "                g.remove_node(n)\n",
    "        except:\n",
    "            pass\n",
    "    with open(f\"./ba/finder_reward_hist/g_{i}.json\", \"w\") as json_file:\n",
    "        json.dump(np.cumsum(reward_lst).tolist(), json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af0d8b0",
   "metadata": {},
   "source": [
    "## FINDER action w.r.t HXA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "satellite-mounting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197\n",
      "194\n",
      "191\n",
      "188\n",
      "184\n",
      "182\n",
      "179\n",
      "176\n",
      "173\n",
      "170\n",
      "168\n",
      "166\n",
      "164\n",
      "161\n",
      "158\n",
      "156\n",
      "154\n",
      "150\n",
      "147\n",
      "142\n",
      "140\n",
      "137\n",
      "133\n",
      "132\n",
      "130\n",
      "127\n",
      "124\n",
      "119\n",
      "117\n",
      "113\n",
      "109\n",
      "105\n",
      "103\n",
      "100\n",
      "97\n",
      "94\n",
      "91\n",
      "88\n",
      "86\n",
      "78\n",
      "77\n",
      "76\n",
      "75\n",
      "74\n",
      "72\n",
      "71\n",
      "69\n",
      "67\n",
      "66\n",
      "65\n",
      "64\n",
      "62\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    g = read_gml(data_dir=\"./ba/\", file_name=f\"g_{i}\")\n",
    "    \n",
    "    df = pd.read_csv(f\"./ba/finder_node_hist/g_{i}.txt\", header=None).rename(columns={0: \"round\", 1: \"node\"})    \n",
    "    for _, (round, n) in df.iterrows():\n",
    "        try:\n",
    "            dc = nx.closeness_centrality(g)\n",
    "            keys = list(dc.keys())\n",
    "            values = list(dc.values())\n",
    "            maxTag = np.argmax(values)\n",
    "            max_node = keys[maxTag]\n",
    "            removed = [n for n in g.neighbors(int(n))] + [int(n)]\n",
    "            for n in removed:\n",
    "                g.remove_node(n)\n",
    "            print(len(g.nodes()))\n",
    "        except:\n",
    "            pass\n",
    "#         \n",
    "    break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de022d0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
